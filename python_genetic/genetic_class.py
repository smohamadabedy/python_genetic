#####################################################################################################################################################
#####################################################################################################################################################
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#██░░░░░░░░░░░░░░█░░░░░░░░░░░░░░█░░░░░░██████████░░░░░░█░░░░░░░░░░░░░░█░░░░░░░░░░░░░░█░░░░░░░░░░█░░░░░░░░░░░░░░█████████████████████████████████████#
#██░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░░░░░░░░░██░░▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█████████████████████████████████████#
#██░░▄▀░░░░░░░░░░█░░▄▀░░░░░░░░░░█░░▄▀▄▀▄▀▄▀▄▀░░██░░▄▀░░█░░▄▀░░░░░░░░░░█░░░░░░▄▀░░░░░░█░░░░▄▀░░░░█░░▄▀░░░░░░░░░░█████████████████████████████████████#
#██░░▄▀░░█████████░░▄▀░░█████████░░▄▀░░░░░░▄▀░░██░░▄▀░░█░░▄▀░░█████████████░░▄▀░░███████░░▄▀░░███░░▄▀░░█████████████████████████████████████████████#
#██░░▄▀░░█████████░░▄▀░░░░░░░░░░█░░▄▀░░██░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░░░░░█████░░▄▀░░███████░░▄▀░░███░░▄▀░░█████████████████████████████████████████████#
#██░░▄▀░░██░░░░░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░██░░▄▀░░██░░▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█████░░▄▀░░███████░░▄▀░░███░░▄▀░░█████████████████████████████████████████████#
#██░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░░░░░█░░▄▀░░██░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░░░░░█████░░▄▀░░███████░░▄▀░░███░░▄▀░░█████████████████████████████████████████████#
#██░░▄▀░░██░░▄▀░░█░░▄▀░░█████████░░▄▀░░██░░▄▀░░░░░░▄▀░░█░░▄▀░░█████████████░░▄▀░░███████░░▄▀░░███░░▄▀░░█████████████████████████████████████████████#
#██░░▄▀░░░░░░▄▀░░█░░▄▀░░░░░░░░░░█░░▄▀░░██░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░░░░░░░░░█████░░▄▀░░█████░░░░▄▀░░░░█░░▄▀░░░░░░░░░░█████████████████████████████████████#
#██░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░██░░░░░░░░░░▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█████░░▄▀░░█████░░▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█████████████████████████████████████#
#██░░░░░░░░░░░░░░█░░░░░░░░░░░░░░█░░░░░░██████████░░░░░░█░░░░░░░░░░░░░░█████░░░░░░█████░░░░░░░░░░█░░░░░░░░░░░░░░█████████████████████████████████████#
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#██░░░░░░░░░░░░░░█░░░░░░█████████░░░░░░░░░░░░░░█░░░░░░░░░░░░░░█░░░░░░░░░░░░░░░░███░░░░░░░░░░█░░░░░░░░░░░░░░█░░░░░░██░░░░░░█░░░░░░██████████░░░░░░███#
#██░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░█████████░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀▄▀░░███░░▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░░░░░░░░░▄▀░░███#
#██░░▄▀░░░░░░▄▀░░█░░▄▀░░█████████░░▄▀░░░░░░░░░░█░░▄▀░░░░░░▄▀░░█░░▄▀░░░░░░░░▄▀░░███░░░░▄▀░░░░█░░░░░░▄▀░░░░░░█░░▄▀░░██░░▄▀░░█░░▄▀▄▀▄▀▄▀▄▀▄▀▄▀▄▀▄▀░░███#
#██░░▄▀░░██░░▄▀░░█░░▄▀░░█████████░░▄▀░░█████████░░▄▀░░██░░▄▀░░█░░▄▀░░████░░▄▀░░█████░░▄▀░░███████░░▄▀░░█████░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░▄▀░░░░░░▄▀░░███#
#██░░▄▀░░░░░░▄▀░░█░░▄▀░░█████████░░▄▀░░█████████░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░░░▄▀░░█████░░▄▀░░███████░░▄▀░░█████░░▄▀░░░░░░▄▀░░█░░▄▀░░██░░▄▀░░██░░▄▀░░███#
#██░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░█████████░░▄▀░░██░░░░░░█░░▄▀░░██░░▄▀░░█░░▄▀▄▀▄▀▄▀▄▀▄▀░░█████░░▄▀░░███████░░▄▀░░█████░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░██░░▄▀░░██░░▄▀░░███#
#██░░▄▀░░░░░░▄▀░░█░░▄▀░░█████████░░▄▀░░██░░▄▀░░█░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░▄▀░░░░█████░░▄▀░░███████░░▄▀░░█████░░▄▀░░░░░░▄▀░░█░░▄▀░░██░░░░░░██░░▄▀░░███#
#██░░▄▀░░██░░▄▀░░█░░▄▀░░█████████░░▄▀░░██░░▄▀░░█░░▄▀░░██░░▄▀░░█░░▄▀░░██░░▄▀░░███████░░▄▀░░███████░░▄▀░░█████░░▄▀░░██░░▄▀░░█░░▄▀░░██████████░░▄▀░░███#
#██░░▄▀░░██░░▄▀░░█░░▄▀░░░░░░░░░░█░░▄▀░░░░░░▄▀░░█░░▄▀░░░░░░▄▀░░█░░▄▀░░██░░▄▀░░░░░░█░░░░▄▀░░░░█████░░▄▀░░█████░░▄▀░░██░░▄▀░░█░░▄▀░░██████████░░▄▀░░███#
#██░░▄▀░░██░░▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀▄▀▄▀▄▀▄▀░░█░░▄▀░░██░░▄▀▄▀▄▀░░█░░▄▀▄▀▄▀░░█████░░▄▀░░█████░░▄▀░░██░░▄▀░░█░░▄▀░░██████████░░▄▀░░███#
#██░░░░░░██░░░░░░█░░░░░░░░░░░░░░█░░░░░░░░░░░░░░█░░░░░░░░░░░░░░█░░░░░░██░░░░░░░░░░█░░░░░░░░░░█████░░░░░░█████░░░░░░██░░░░░░█░░░░░░██████████░░░░░░███#
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████#
#####################################################################################################################################################
#####################################################################################################################################################

from    datetime             import datetime 
from    time                 import time  
from    numpy                import random
import  numpy                as np
import  matplotlib.pyplot    as plt
import  matplotlib.gridspec  as gridspec
import  math
import  json
import  csv
import  os

plt.rcParams.update({'font.size': 8})
      
# ----------------- Dependency Classes --------------------
from .selection     import Selection
from .probability   import Probability
from .sorting       import Sorting

# ---------------- Main Population Class ------------------
class GA(Sorting, Selection, Probability):

    def __init__(self,settings,fitness):
        self.timestamp      = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Define the search space boundaries for each dimension       
        self.space          = settings['space']
        self.pspace         = np.array(self.space)                  # Convert to NumPy array for vectorized operations
        self.ndim           = self.pspace.shape[0]                  # Number of decision variables (dimensions)
        self.pdim           = settings.get('total_population',50)   # Total number of individuals in the population
        self.cdim           = 2 * math.ceil(settings.get('selection_rate',0.5) * self.pdim / 2) # Number of parents selected for breeding (ensures even count)
        self.mdim           = math.ceil(settings.get('mutation_rate',0.05) * self.pdim)         # Number of individuals to mutate per generation
        
        # Template (control parameters)
        self.slct_method    = settings['selection']             # Selection method (e.g., tournament, roulette)
        self.sort_method    = settings['sorting']               # Sorting method for evaluating individuals
        self.prob_method    = settings['probability']           # Probability distribution method for selection
       
        # Selection pressure coefficien
        self.prob_press     = settings['probability_pressure']  
        
        # Fitness function (objective function to minimiz)
        self.gval_function  = fitness
        
        # Initialize the population
        self.pop            = self._init_pop()
        self._feed_population();    # Precompute and attach evaluations
        
        # Result saving configuration
        self.folder         = settings.get('folder','Results')
        self.save_prefix    = settings.get('save_prefix','results')
        os.makedirs(f"{self.folder}_{self.timestamp}", exist_ok=True)
        self.json_path      = os.path.join(f"{self.folder}_{self.timestamp}", f"{self.save_prefix}_{self.timestamp}.json")
        self.csv_path       = os.path.join(f"{self.folder}_{self.timestamp}", f"{self.save_prefix}_{self.timestamp}.csv")
        
        # Historical tracking for each iteration (used for post-analysis and visualization)
        self.history        = []
    
    # Generate a random vector (candidate solution) within the defined search space
    def _generate_initial_value(self):
        return random.uniform(self.pspace[:, 0], self.pspace[:, 1])
        
    # Create a single individual (particle) with associated metadata
    def _create_particle(self, value=None):
        value = value if value is not None else self._generate_initial_value()
        return {
            'pr'            : 1,                                            # Initial selection probability (could be updated later)
            'age'           : 0,                                            # Age of the particle (optional, used in some aging strategies)
            'value'         : value.tolist(),                               # Position
            'evaluation'    : self.gval_function(value.tolist())            # Fitness value
        }
        
    # Initialize the entire population with random particles
    def _init_pop(self):
        return np.array([self._create_particle() for _ in range(self.pdim)])

    def _feed_population(self):
        self.generation = np.array([])
        self.parents    = np.array([])
        self.child      = np.array([])
        self.mutation   = np.array([])
        self.set_prob(self.pop).sort_pop(self.pop)
        for p in self.pop:
            p['age'] += 1
        return self

    # Generate a random vector of blending coefficients for crossover,
    def _generate_alpha(self):
        # sampled uniformly from the range [-1.5, 1.5] for each dimension
        return random.uniform(-1.5, 1.5, self.ndim)
    
    # Perform linear crossover between two parents using alpha
    def _create_children(self, p1, p2, alpha):
        v1 = alpha * np.array(p1['value']) + (1 - alpha) * np.array(p2['value'])
        v2 = (1 - alpha) * np.array(p1['value']) + alpha * np.array(p2['value'])
        # Return two new individuals (particles)
        return [self._create_particle(v1), self._create_particle(v2)]

    # Sort the population in-place using the configured sorting method (e.g., by fitness)
    def sort_pop(self, pop):
        self.bubble_sort(pop)
        return self

    # Set selection probabilities for individuals using the specified pressure function
    def set_prob(self, pop):
        # The probability is typically based on ranking or fitness values, here based on exponential scaling
        self.set_exp_pr(pop, self.prob_press)
        return self
    
    # Select a subset of the population to be used as parents for crossover
    def mate(self):
        # Uses the configured selection strategy (e.g., roulette, tournament)
        self.parents = self.simple_select()
        return self

    # Perform crossover by randomly selecting and pairing parents to generate offspring.
    def breed(self):
        parenting       = list(self.parents.copy())
        self.child      = []
        while len(parenting) >= 2:
            i1          = random.randint(len(parenting))
            p1          = parenting.pop(i1)
            i2          = random.randint(len(parenting))
            p2          = parenting.pop(i2)
            alpha       = self._generate_alpha()
            self.child.extend(self._create_children(p1, p2, alpha))
        self.child      = np.array(self.child)
        return self
    
    # Generate a set of new individuals (mutants) randomly to maintain diversity.
    def mutate(self):
        self.mutation   = np.array([self._create_particle() for _ in range(self.mdim)])
        return self
        
    # Form the new population by combining current population, offspring, and mutations.
    # Then select the top individuals for the next generation.
    def repopulate(self):
        self.generation = np.concatenate((self.pop, self.child, self.mutation))
        self.set_prob(self.generation).sort_pop(self.generation)
        self.pop        = self.generation[:self.pdim].copy()
        self._feed_population()
        return self

    # Save the optimization history to both JSON and CSV formats for later analysis.
    def save_history(self):
        with open(self.json_path, 'w') as f_json:
            json.dump(self.history, f_json, indent=2)

        with open(self.csv_path, 'w', newline='') as f_csv:
            writer = csv.DictWriter(f_csv, fieldnames=[
                "iteration", "best_score", "mean_score", "std_score",
                "best_position", "best_position_mean", "best_position_std"
            ])
            writer.writeheader()
            for row in self.history:
                writer.writerow(row)
                
    # Log the metrics for the current generation including fitness stats and best individual.
    def log_iteration(self, iteration):
        fitness = [p['evaluation'] for p in self.pop]
        best = self.pop[0]
        best_score = float(best['evaluation'])
        best_position = best['value']

        row = {
            "iteration": iteration + 1,
            "best_score": best_score,
            "mean_score": float(np.mean(fitness)),
            "std_score": float(np.std(fitness)),
            "best_position": best_position,
            "best_position_mean": float(np.mean(best_position)),
            "best_position_std": float(np.std(best_position)),
        }

        self.history.append(row)

        formatted_position = ",".join(f"{x:.3f}" for x in best_position)
        print(f"Iter {iteration+1}/max, Best Position: {formatted_position}, "
                   f"Best Score: {best_score:.4f}, Mean Score: {np.mean(fitness):.4f}")
     
     
    # Plot Final Optimization Results (must be called explicitly)
    def plot(self):
        iterations  = [row["iteration"]             for row in self.history]
        best_scores = [row["best_score"]            for row in self.history]
        mean_scores = [row["mean_score"]            for row in self.history]
        std_scores  = [row["std_score"]             for row in self.history]
        pos_mean    = [row["best_position_mean"]    for row in self.history]
        pos_std     = [row["best_position_std"]     for row in self.history]

        fig = plt.figure(figsize=(6, 3))
        gs = gridspec.GridSpec(2, 3, height_ratios=[1,  1.2])
        
        # Best Score (top-left)
        ax1 = fig.add_subplot(gs[0, 0])
        ax1.plot(iterations, best_scores, color='blue', linewidth=2)
        ax1.set_ylabel("Best Score")
        ax1.set_title("Best Score")
        ax1.grid(True)

        # Mean Score (top-right)
        ax2 = fig.add_subplot(gs[0, 1])
        ax2.plot(iterations, mean_scores, color='green', linestyle='--')
        ax2.set_ylabel("Mean Score")
        ax2.set_title("Mean Score")
        ax2.grid(True)

        # Std Score (second row, full width)
        ax3 = fig.add_subplot(gs[0, 2])
        ax3.plot(iterations, std_scores, color='orange')
        ax3.set_ylabel("Std Score")
        ax3.set_title("Fitness Standard Deviation")
        ax3.grid(True)

        # Best Position Mean and Std (third row, full width)
        ax4 = fig.add_subplot(gs[1, :])
        ax4.plot(iterations, pos_mean, label="Best Position Mean")
        ax4.plot(iterations, pos_std, label="Best Position Std", linestyle='--')
        ax4.set_xlabel("Iteration")
        ax4.set_ylabel("Position Stats")
        ax4.set_title("Best Position Statistics")
        ax4.legend()
        ax4.grid(True)

        plt.tight_layout()
        plt.show()
